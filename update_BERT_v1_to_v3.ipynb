{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+mUEE8Avy/G3eqNpAiV2v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","# this is some sort of bug?? https://github.com/tensorflow/hub/issues/903\n","os.environ['TF_USE_LEGACY_KERAS']='1'"],"metadata":{"id":"0TlhHhHO5f7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWJOOQE15Eqd"},"outputs":[],"source":["from google.colab import drive\n","# Mount Google Drive for model and csv up/download\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","\n","# Paths to current TF Hub modules (orignal model built with bert_en_uncased_preprocess/1)\n","tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n","# Matching encoder used for original model\n","tfhub_handle_encoder = \"https://tfhub.dev/google/experts/bert/pubmed/2\"\n","\n","# rebuild blank BiomchBERT\n","def build_classifier_model():\n","    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n","    encoder_inputs = preprocessing_layer(text_input)\n","    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","    outputs = encoder(encoder_inputs)\n","    net = outputs['pooled_output']\n","    net = tf.keras.layers.Dropout(0.1)(net)\n","    net = tf.keras.layers.Dense(27, activation='softmax', name='classifier')(net)\n","    return tf.keras.Model(text_input, net)\n","\n","model = build_classifier_model()\n"],"metadata":{"id":"3DmSZhEK5QRI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# temp save to get variables and blank .pb file\n","tf.saved_model.save(model, \"/content/gdrive/My Drive/test\")"],"metadata":{"id":"Koa7QYw385JJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# what do the variable names (trainable weights) look like in blank model\n","vars_in_ckpt = tf.train.list_variables('/content/gdrive/My Drive/test/variables/variables')\n","for name, shape in vars_in_ckpt:\n","    print(name, shape)\n"],"metadata":{"id":"znkJrP8G9Y58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# what do the variable names (trainable weights) look like in original model\n","vars_in_ckpt = tf.train.list_variables('/content/gdrive/My Drive/BiomchBERT/Data/BiomchBERT/variables/variables')\n","for name, shape in vars_in_ckpt:\n","    print(name, shape)"],"metadata":{"id":"jYm_NvEm6tgB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What do the variable names (trainable weights) look like in the actual blank model\n","for var in model.trainable_variables:\n","  print(var.name, var.shape)\n"],"metadata":{"id":"mRH6hAKO7JNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# need to rename old variable names to match new model weight names in order to load in old weights\n","import re\n","\n","# fix old names to reflect weight names in new model\n","def normalize_old_name(old_name):\n","    # Remove \"layer_with_weights-[number]/\" prefix if present\n","    old_name = re.sub(r\"^layer_with_weights-\\d+/\", \"\", old_name)\n","    # Replace `.S` (serialized slash) back to `/`\n","    old_name = old_name.replace(\".S\", \"/\")\n","    # Remove any :<digit> that appears before a slash or at end\n","    old_name = re.sub(r\":\\d+(?=/|$)\", \"\", old_name)\n","    # Remove checkpoint-specific attributes\n","    old_name = old_name.replace(\".ATTRIBUTES/VARIABLE_VALUE\", \"\")\n","    # Remove trailing slash if it exists\n","    old_name = old_name.rstrip(\"/\")\n","    return old_name\n","\n","# load the old weight names\n","ckpt_path = '/content/gdrive/My Drive/BiomchBERT/Data/BiomchBERT/variables/variables'\n","old_ckpt_reader = tf.train.load_checkpoint(ckpt_path)\n","old_var_names = old_ckpt_reader.get_variable_to_shape_map().keys()\n","\n","# fix old names\n","old_vars_normalized = {normalize_old_name(k): k for k in old_var_names}\n","\n","# Build mapping dictionary\n","mapping = {}\n","for new_w in model.weights:\n","    new_name = new_w.name.replace(\":0\", \"\")  # remove TF suffix\n","    if new_name in old_vars_normalized:\n","        mapping[new_name] = old_vars_normalized[new_name]\n","    else:\n","        print(f\"❌ No match for: {new_name}\")\n","\n","# Handle known special cases\n","mapping[\"classifier/kernel\"] = old_vars_normalized.get(\"kernel\", None)\n","mapping[\"classifier/bias\"] = old_vars_normalized.get(\"bias\", None)\n","\n","# Check mapping\n","for new_name, old_name in mapping.items():\n","    print(f\"{new_name}  <--  {old_name}\")\n","\n","# Now load old weights in manually and assign to new model\n","for w in model.weights:\n","    new_name = w.name.replace(\":0\", \"\")\n","    if new_name in mapping and mapping[new_name] is not None:\n","        w.assign(old_ckpt_reader.get_tensor(mapping[new_name]))\n","\n","print(\"✅ Weights loaded from old checkpoint into new model\")"],"metadata":{"id":"X1ee2JXLo-NL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save next to original BiomchBERT\n","tf.saved_model.save(model, '/content/gdrive/My Drive/BiomchBERT/Data/BiomchBERT_V3/')"],"metadata":{"id":"LYIzivBVrp8Z"},"execution_count":null,"outputs":[]}]}