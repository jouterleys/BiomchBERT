{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"classify_papers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XJG5shp08CGC"},"source":["Uses Fine-Tuned BERT network to classify biomechanics papers from PubMed"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnZ8CI-rwNOY","executionInfo":{"status":"ok","timestamp":1647531381986,"user_tz":240,"elapsed":436,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}},"outputId":"2b2e8ec5-6cc0-48b5-86da-7c3448dd684b"},"source":["# Check date\n","!rm /etc/localtime\n","!ln -s /usr/share/zoneinfo/America/Los_Angeles /etc/localtime\n","!date\n","# might need to restart runtime if timezone didn't change"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Mar 17 08:36:20 PDT 2022\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6klLdde-78nI","executionInfo":{"status":"ok","timestamp":1647531530699,"user_tz":240,"elapsed":138970,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}},"outputId":"d984c258-8e33-416b-924b-0ea9f921deb9"},"source":["## Install & load libraries\n","\n","!pip install tensorflow==2.7.0\n","\n","try:\n","  from official.nlp import optimization\n","except:\n","  !pip install -q -U tf-models-official==2.4.0\n","  from official.nlp import optimization\n","try:\n","  from Bio import Entrez\n","except:\n","  !pip install -q -U biopython\n","  from Bio import Entrez\n","try:\n","  import tensorflow_text as text\n","except:\n","  !pip install -q -U tensorflow_text==2.7.3\n","  import tensorflow_text as text\n"," \n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import tensorflow as tf  # probably have to lock version\n","import string\n","import datetime\n","from bs4 import BeautifulSoup\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import load_model\n","import tensorflow_hub as hub\n","from google.colab import drive\n","import datetime as dt\n","\n","#Define date range\n","today = dt.date.today()\n","yesterday = today - dt.timedelta(days=1)\n","week_ago = yesterday - dt.timedelta(days=7)  # ensure overlap in pubmed search\n","days_ago_6 = yesterday - dt.timedelta(days=6) # for text output\n","\n","# Mount Google Drive for model and csv up/download\n","drive.mount('/content/gdrive')\n","print(today)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.7.0\n","  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n","\u001b[K     |████████████████████████████████| 489.6 MB 25 kB/s \n","\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.24.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.5)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (13.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.10.0.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.13.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n","Collecting keras<2.8,>=2.7.0rc0\n","  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 36.2 MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n","  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n","\u001b[K     |████████████████████████████████| 463 kB 45.5 MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.44.0)\n","Collecting gast<0.5.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n","Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.0\n","    Uninstalling tensorflow-2.8.0:\n","      Successfully uninstalled tensorflow-2.8.0\n","Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n","\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 27.7 MB/s \n","\u001b[K     |████████████████████████████████| 234 kB 22.9 MB/s \n","\u001b[K     |████████████████████████████████| 47.8 MB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 41.9 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 40.9 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 39.3 MB/s \n","\u001b[K     |████████████████████████████████| 99 kB 7.4 MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 2.3 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 4.9 MB 5.4 MB/s \n","\u001b[?25h[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Mounted at /content/gdrive\n","2022-03-17\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaSczx4IuQ0Y","executionInfo":{"status":"ok","timestamp":1647531615260,"user_tz":240,"elapsed":56789,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}},"outputId":"4a2a8a1e-3bbb-400e-f5be-c1fad4d28580"},"source":["# Define Search Criteria ----\n","def search(query):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.esearch(db='pubmed',\n","                            sort='most recent',\n","                            retmax='5000',\n","                            retmode='xml',\n","                            datetype='pdat',  # pdat is published date, edat is entrez date. \n","                            # reldate=7,  # only within n days from now\n","                            mindate= min_date,\n","                            maxdate= max_date,  # for searching date range\n","                            term=query)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Perform Search and Pull Paper Titles ----\n","def fetch_details(ids):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.efetch(db='pubmed',\n","                           retmode='xml',\n","                           id=ids)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Make the stop words for string cleaning ----\n","def html_strip(text):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.replace('[','').replace(']','')\n","    return text\n","\n","def clean_str(text, stops):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.split()\n","    return ' '.join([word for word in text if word not in stops])\n","\n","stop = list(stopwords.words('english'))\n","stop_c = [string.capwords(word) for word in stop]\n","for word in stop_c:\n","    stop.append(word)\n","\n","new_stop = ['The', 'An', 'A', 'Do', 'Is', 'In', 'StringElement', \n","            'NlmCategory', 'Label', 'attributes', 'INTRODUCTION',\n","            'METHODS', 'BACKGROUND', 'RESULTS', 'CONCLUSIONS']\n","for s in new_stop:\n","    stop.append(s)\n","\n","# Search terms (can test string with Pubmed Advanced Search) ----\n","# search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')\n","min_date = week_ago.strftime('%m/%d/%Y')\n","max_date = yesterday.strftime('%m/%d/%Y')\n","search_results = search('(biomech*[Title/Abstract] OR locomot*[Title/Abstract] NOT opiod*[Title/Abstract] NOT pharm*[Journal] NOT mouse[Title/Abstract] NOT drosophil*[Title/Abstract] NOT mice[Title/Abstract] NOT rats*[Title/Abstract] NOT elegans[Title/Abstract])')\n","id_list = search_results['IdList']\n","papers = fetch_details(id_list)\n","print(len(papers['PubmedArticle']), 'Papers found')\n","\n","titles, full_titles, keywords, authors, links, journals, abstracts = ([] for i in range(7))\n","\n","for paper in papers['PubmedArticle']:\n","    # clean and store titles, abstracts, and links\n","    t = clean_str(paper['MedlineCitation']['Article']['ArticleTitle'], \n","                  stop).replace('[','').replace(']','').capitalize()  # rm brackets that survived beautifulsoup, sentence case\n","    titles.append(t)\n","    full_titles.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n","    pmid = paper['MedlineCitation']['PMID']\n","    links.append('[URL=\"https://www.ncbi.nlm.nih.gov/pubmed/{0}\"]{1}[/URL]'.format(pmid, html_strip(paper['MedlineCitation']['Article']['ArticleTitle'])))\n","    try:\n","        abstracts.append(clean_str(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0], \n","                                    stop).replace('[','').replace(']','').capitalize())  # rm brackets that survived beautifulsoup, sentence case\n","    except:\n","        abstracts.append('')\n","\n","    # clean and store authors\n","    auths = []\n","    try:\n","        for auth in paper['MedlineCitation']['Article']['AuthorList']:\n","            try:  # see if there is a last name and initials\n","                auth_name = [auth['LastName'], auth['Initials'] + ',']\n","                auth_name = ' '.join(auth_name)\n","                auths.append(auth_name)\n","            except:\n","                if 'LastName' in auth.keys():  # maybe they don't have initials\n","                    auths.append(auth['LastName'] + ',')\n","                else:  # no last name\n","                    auths.append('')\n","                    print(paper['MedlineCitation']['Article']['ArticleTitle'],\n","                          'has an issue with an author name:')\n","\n","    except:\n","        auths.append('AUTHOR NAMES ERROR')\n","        print(paper['MedlineCitation']['Article']['ArticleTitle'], 'has no author list?')\n","    # compile authors\n","    authors.append(' '.join(auths).replace('[','').replace(']',''))  # rm brackets in names\n","    # journal names\n","    journals.append(paper['MedlineCitation']['Article']['Journal']['Title'].replace('[','').replace(']',''))  # rm brackets\n","\n","    # store keywords \n","    if paper['MedlineCitation']['KeywordList'] != []:\n","        kwds = []\n","        for kw in paper['MedlineCitation']['KeywordList'][0]:\n","            kwds.append(kw[:])\n","        keywords.append(', '.join(kwds).lower())\n","    else:\n","      keywords.append('')\n","\n","# Put Titles, Abstracts, Authors, Journal, and Keywords into dataframe\n","papers_df = pd.DataFrame({'title': titles,\n","                          'keywords': keywords,\n","                          'abstract': abstracts,\n","                          'authors': authors,\n","                          'journal': journals,\n","                          'links': links,\n","                          'raw_title': full_titles,\n","                          'mindate': min_date,\n","                          'maxdate': max_date})\n","\n","\n","# remove papers with no title or no authors\n","for index, row in papers_df.iterrows():\n","    if row['title'] == '' or row['authors'] == 'AUTHOR NAMES ERROR':\n","        papers_df.drop(index, inplace=True)\n","papers_df.reset_index(drop=True, inplace=True)\n","\n","# join titles and abstract\n","papers_df['BERT_input'] = pd.DataFrame(papers_df['title'] + ' ' + papers_df['abstract'])\n","\n","# Load Fine-Tuned BERT Network ----\n","model = tf.saved_model.load('/content/gdrive/My Drive/BiomchBERT/Data/BiomchBERT/')\n","print('Loaded model from disk')\n","\n","# Load Label Encoder ----\n","le = LabelEncoder()\n","le.classes_ = np.load('/content/gdrive/My Drive/BiomchBERT/Data/BERT_label_encoder.npy')\n","print('Loaded Label Encoder')\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["102 Papers found\n","Low-Density Pedicle Screw Constructs Are Associated with Lower Incidence of Proximal Junctional Failure in Adult Spinal Deformity Surgery. has an issue with an author name:\n","Loaded model from disk\n","Loaded Label Encoder\n"]}]},{"cell_type":"code","metadata":{"id":"55tVgCM--ktr","executionInfo":{"status":"ok","timestamp":1647531647069,"user_tz":240,"elapsed":3658,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}}},"source":["# Predict Paper Topic ----\n","predicted_topic = model(papers_df['BERT_input'], training=False)  # will run out of GPU memory (14GB) if predicting more than ~2000 title+abstracts at once"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvD9JQj7-2_e","executionInfo":{"status":"ok","timestamp":1647531651500,"user_tz":240,"elapsed":1631,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}},"outputId":"448689da-6251-4554-db42-511b60f9edf5"},"source":["# Determine Publications that BiomchBERT is unsure about ----\n","topics, pred_val_str = ([] for i in range(2))\n","\n","for pred_prob in predicted_topic:\n","    pred_val = np.max(pred_prob)\n","    if pred_val > 1.5 * np.sort(pred_prob)[-2]:  # Is top confidence score more than 1.5x the second best confidence score?\n","        topics.append(le.inverse_transform([np.argmax(pred_prob)])[0])\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        # pred_val_str.append(pred_val * 100)  # just report top category\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))  # report top 2 categories\n","    else:\n","        topics.append('UNKNOWN')\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))\n","        \n","papers_df['topic'] = topics\n","papers_df['pred_val'] = pred_val_str\n","\n","print('BiomchBERT is unsure about {0} papers\\n'.format(len(papers_df[papers_df['topic'] == 'UNKNOWN'])))\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["BiomchBERT is unsure about 9 papers\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeacO2b3WHFu","executionInfo":{"status":"ok","timestamp":1647532120720,"user_tz":240,"elapsed":464334,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}},"outputId":"ed521557-fb5c-4a4a-db3a-442461aa3ab4"},"source":["\n","# Prompt User to decide for BiomchBERT ----\n","unknown_papers = papers_df[papers_df['topic'] == 'UNKNOWN']\n","for indx, paper in unknown_papers.iterrows():\n","  print(paper['raw_title'])\n","  print(paper['journal'])\n","  print(paper['pred_val'])\n","  print()\n","  splt_str = paper['pred_val'].split(';')\n","  options = [str for pred_cls in splt_str for str in le.classes_ if (str in pred_cls)]\n"," \n"," \n","  choice = input('(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? ')\n","  print()\n","  if choice == '1':\n","    papers_df.iloc[indx]['topic'] = str(options[0])\n","  elif choice == '2':\n","    papers_df.iloc[indx]['topic'] = str(options[1])\n","  elif choice == 'o':\n","    # print all categories so you can select\n","    for i in zip(range(len(le.classes_)),le.classes_):\n","      print(i)  \n","    new_cat = input('Enter number of new class or type \"r\" to remove paper: ')\n","    print()\n","    if new_cat == 'r':\n","      papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","    else:\n","      papers_df.iloc[indx]['topic'] = le.classes_[int(new_cat)] \n","  elif choice == 'r':\n","    papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n"," \n","print('Removing {0} papers\\n'.format(len(papers_df[papers_df['topic'] == '_REMOVE_'])))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["A biomechanical investigation of the efficiency hypothesis of hafted tool technology.\n","Journal of the Royal Society, Interface\n","38.9% ORTHOPAEDICS/SURGERY; 27.5% ORTHOPAEDICS/SPINE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 11\n","\n","Applications of Biomechanical Foot Models to Evaluate Dance Movements Using Three‑Dimensional Motion Capture: A Review of the Literature.\n","Journal of dance medicine & science : official publication of the International Association for Dance Medicine & Science\n","43.9% GAIT/LOCOMOTION; 39.0% ORTHOPAEDICS/SURGERY\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 0\n","\n","Diagnosis and Treatment of Musculotendinous Deficiencies of the Hip.\n","The Journal of arthroplasty\n","37.4% MUSCLE; 33.8% POSTURE/BALANCE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 16\n","\n","Applying common filtering processes to Global Navigation Satellite System-derived acceleration during team sport locomotion.\n","Journal of sports sciences\n","49.0% ORTHOPAEDICS/SURGERY; 43.5% GAIT/LOCOMOTION\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 11\n","\n","Computational analysis of Lisfranc surgical repairs.\n","Journal of orthopaedic research : official publication of the Orthopaedic Research Society\n","30.4% MUSCLE; 27.5% HAND/FINGER/FOOT/TOE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 16\n","\n","Preliminary Report on the Train the Brain Project: Sensorimotor Neural Correlates of Anterior Cruciate Ligament Injury Risk Biomechanics - Part I.\n","Journal of athletic training\n","32.5% METHODS; 32.1% POSTURE/BALANCE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 21\n","\n","Rapid X-Ray-Based 3-D Finite Element Modeling of Medial Knee Joint Cartilage Biomechanics During Walking.\n","Annals of biomedical engineering\n","53.4% HAND/FINGER/FOOT/TOE; 39.5% EVOLUTION/ANTHROPOLOGY\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 10\n","\n","Genipin-crosslinked collagen scaffolds inducing chondrogenesis: a mechanical and biological characterization.\n","Journal of biomedical materials research. Part A\n","50.6% EVOLUTION/ANTHROPOLOGY; 46.9% PROSTHETICS/ORTHOTICS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 23\n","\n","A biomimetic remora disc with tunable, reversible adhesion for surface sliding and skimming.\n","Bioinspiration & biomimetics\n","49.1% ORTHOPAEDICS/SPINE; 34.9% CELLULAR/SUBCELLULAR\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: r\n","\n","Removing 1 papers\n","\n"]}]},{"cell_type":"code","metadata":{"id":"Deqf5q7BdTAJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647532134303,"user_tz":240,"elapsed":1158,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}},"outputId":"89ae9dd6-4c11-4be5-9f09-c51225488a47"},"source":["# Double check that none of these papers were included in past literature updates ----\n","# load prior papers\n","# papers_df.to_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv', index=False)  # run ONLY if there are no prior papers\n","prior_papers = pd.read_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv')\n","prior_papers.dropna(subset=['title'], inplace=True)\n","prior_papers.reset_index(drop=True, inplace=True)\n","\n","# NEED TO DO: find matching papers between current week and prior papers using Pubmed ID since titles can change from ahead of print to final version.\n","# match = papers_df['links'].split(']')[0].isin(prior_papers['links'].split(']')[0])\n","\n","match = papers_df['title'].isin(prior_papers['title'])  # boolean\n","print('Removing {0} papers found in prior literature updates\\n'.format(sum(match)))\n","# filter and check if everything accidentally was removed\n","filtered_papers_df = papers_df.drop(papers_df[match].index)\n","if filtered_papers_df.shape[0] < 1:\n","    raise ValueError('might have removed all the papers for some reason. ')\n","else:\n","    papers_df = filtered_papers_df\n","    papers_df.reset_index(drop=True, inplace=True)\n","    updated_prior_papers = pd.concat([prior_papers, papers_df], axis=0)\n","    updated_prior_papers.reset_index(drop=True, inplace=True)\n","    updated_prior_papers.to_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv', index=False)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Removing 11 papers found in prior literature updates\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fQKyxoBF36B","executionInfo":{"status":"ok","timestamp":1647532282545,"user_tz":240,"elapsed":336,"user":{"displayName":"Jereme Outerleys","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giywlp9digv8ZE0_DYzKU64qnOYWaH48ArhTZVs=s64","userId":"15452485930552153510"}},"outputId":"f14c9d86-442b-438f-f6e6-51d7437dea78"},"source":["# Create Text File for Biomch-L ----\n","# Compile papers grouped by topic\n","txtname = '/content/gdrive/My Drive/BiomchBERT/Updates/' + today.strftime(\"%Y-%m-%d\") + '-litupdate.txt'\n","txt = open(txtname, 'w', encoding='utf-8')\n","txt.write('[SIZE=16px][B]LITERATURE UPDATE[/B][/SIZE]\\n')\n","txt.write(days_ago_6.strftime(\"%b %d, %Y\") + ' - '+ yesterday.strftime(\"%b %d, %Y\")+'\\n')  # a week ago from yesterday.\n","txt.write(\n","    \"\"\"\n","Literature search terms: biomech* & locomot*\n","\n","Publications are classified by [URL=\"https://www.ryan-alcantara.com/projects/p88_BiomchBERT/\"]BiomchBERT[/URL], a neural network trained on past Biomch-L Literature Updates. BiomchBERT is managed by [URL=\"https://jouterleys.github.io\"]Jereme Outerleys[/URL], a Doctoral Student at Queen's University. Each publication has a score (out of 100%) reflecting how confident BiomchBERT is that the publication belongs in a particular category (top 2 shown). If something doesn't look right, email jereme.outerleys[at]queensu.ca.\n","\n","Twitter: [URL=\"https://www.twitter.com/jouterleys\"]@jouterleys[/URL]. \n","\n","\n","    \"\"\"\n","    )\n","\n","# Write papers to text file grouped by topic ----\n","topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n","\n","for topic in topic_list:\n","    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop=True))\n","    txt.write('\\n')\n","    # TOPIC NAME (with some cleaning)\n","    if topic == '_REMOVE_':\n","      continue\n","    elif topic == 'UNKNOWN':\n","        txt.write('[SIZE=16px][B]*Papers BiomchBERT is unsure how to classify*[/B][/SIZE]\\n')\n","    elif topic == 'CARDIOVASCULAR/CARDIOPULMONARY':\n","      topic = 'CARDIOVASCULAR/PULMONARY'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'CELLULAR/SUBCELLULAR':\n","      topic = 'CELLULAR'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SURGERY':\n","      topic = 'ORTHOPAEDICS (SURGERY)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SPINE':\n","      topic = 'ORTHOPAEDICS (SPINE)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    else:\n","        txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    # HYPERLINKED PAPERS, AUTHORS, JOURNAL NAME\n","    for i, paper in enumerate(papers_subset['links']):\n","        txt.write('[B]%s[/B] ' % paper)\n","        txt.write('%s ' % papers_subset['authors'][i])\n","        txt.write('[I]%s[/I]. ' % papers_subset['journal'][i])\n","        # CONFIDENCE SCORE (BERT softmax categorical crossentropy)\n","        try:\n","            txt.write('(%.1f%%) \\n\\n' % papers_subset['pred_val'][i])\n","        except:\n","            txt.write('(%s)\\n\\n' % papers_subset['pred_val'][i]) \n","\n","txt.write('[SIZE=16px][B]*PICK OF THE WEEK*[/B][/SIZE]\\n')\n","txt.close()\n","print('Literature Update Exported for Biomch-L')\n","print('Location:', txtname)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Literature Update Exported for Biomch-L\n","Location: /content/gdrive/My Drive/BiomchBERT/Updates/2022-03-17-litupdate.txt\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"McR_o-iu7Czf"},"execution_count":null,"outputs":[]}]}